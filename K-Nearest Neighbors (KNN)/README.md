# K-Nearest Neighbors (KNN) Classifier

This program implements a **K-Nearest Neighbors (KNN)** classifier from scratch using Python and NumPy.  
It predicts the class of new data points based on the closest training points and visualizes the results.

## What it does
- Implements the **KNN algorithm** from scratch  
- Uses **Euclidean distance** to find the nearest neighbors  
- Supports **1D and 2D data points**  
- Predicts the class of new points using **majority voting**  
- Visualizes **training points, test points, and decision regions**  
- Shows how **changing k** affects classification

## Real-life examples
1. Classifying whether a customer will buy a product based on features  
2. Detecting spam emails based on similarity to labeled examples  
3. Medical diagnosis based on patient measurements (e.g., tumor classification)

## What I learned
- How **distance metrics** determine nearest neighbors  
- How **majority voting** produces predictions  
- How KNN can classify both **1D and 2D datasets**  
- How to **visualize decision boundaries** for better understanding of the model  
- How to implement a **machine learning algorithm from scratch** without external libraries
