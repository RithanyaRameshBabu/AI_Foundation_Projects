# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BxfeULOk32ZSn30yxD0Slet5IlWUP-8P
"""

import numpy as np
import matplotlib.pyplot as plt

# ---------------- Data for AND, OR, NAND ----------------
gates = {
    "AND": np.array([0,0,0,1]),
    "OR":  np.array([0,1,1,1]),
    "NAND":np.array([1,1,1,0])
}

X = np.array([[0,0],[0,1],[1,0],[1,1]])

# ---------------- Perceptron Training Function ----------------
def train_perceptron(X, y, lr=0.1, epochs=10):
    w = np.zeros(2)
    b = 0
    for _ in range(epochs):
        for xi, target in zip(X, y):
            z = np.dot(w, xi) + b
            pred = 1 if z > 0 else 0
            error = target - pred
            w += lr * error * xi
            b += lr * error
    return w, b

# ---------------- Plotting ----------------
plt.figure(figsize=(12,4))

for idx, (gate_name, y) in enumerate(gates.items()):
    w, b = train_perceptron(X, y)

    # Test predictions
    preds = [1 if np.dot(w, xi)+b>0 else 0 for xi in X]
    print(f"{gate_name} Gate Predictions: {preds}  Weights: {w}, Bias: {b}")

    # Plot
    plt.subplot(1,3,idx+1)
    for xi, label in zip(X, y):
        color = 'red' if label==0 else 'blue'
        plt.scatter(xi[0], xi[1], c=color, s=200)

    # Decision boundary: w1*x + w2*y + b = 0 -> y = -(w1*x + b)/w2
    if w[1] != 0:  # avoid division by zero
        x_vals = np.array([-0.2,1.2])
        y_vals = -(w[0]*x_vals + b)/w[1]
        plt.plot(x_vals, y_vals, 'k--', label="Decision Boundary")

    plt.title(f"{gate_name} Gate")
    plt.xlim(-0.2,1.2)
    plt.ylim(-0.2,1.2)
    plt.xlabel("Input 1")
    plt.ylabel("Input 2")
    plt.legend()

plt.suptitle("Perceptron Learning - Logic Gates", fontsize=16)
plt.tight_layout()
plt.show()